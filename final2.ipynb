{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "81475157aa4f32e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T23:50:10.544386Z",
     "start_time": "2026-02-03T23:50:10.538221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib3\n",
    "import requests\n",
    "import requests_cache\n",
    "\n",
    "print(urllib3.__version__)\n",
    "print(requests.__version__)\n",
    "print(requests_cache.__version__)\n"
   ],
   "id": "8ab83812abac6f64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.18\n",
      "2.31.0\n",
      "1.2.1\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T23:50:12.944021Z",
     "start_time": "2026-02-03T23:50:12.938162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "abuja_latitude = 9.0765\n",
    "abuja_longitude = 7.3986\n",
    "\n",
    "print(f\"Abuja Latitude: {abuja_latitude}\")\n",
    "print(f\"Abuja Longitude: {abuja_longitude}\")"
   ],
   "id": "ea77cb45a709c555",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abuja Latitude: 9.0765\n",
      "Abuja Longitude: 7.3986\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T23:50:18.633957Z",
     "start_time": "2026-02-03T23:50:18.618935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "# 2. Create a requests_cache.CachedSession object to cache API responses\n",
    "# Cache API requests for an hour to reduce redundant calls\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "\n",
    "# 3. Initialize the openmeteo_requests client with the cached session\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "# 4. Define the URL for the Open-Meteo Archive API\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# 5. Specify the parameters for the API request\n",
    "params = {\n",
    "    \"latitude\": abuja_latitude,\n",
    "    \"longitude\": abuja_longitude,\n",
    "    \"start_date\": \"2024-01-01\",\n",
    "    \"end_date\": \"2024-01-07\",\n",
    "    \"daily\": [\n",
    "        \"weather_code\",\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"temperature_2m_mean\",\n",
    "        \"apparent_temperature_max\",\n",
    "        \"apparent_temperature_min\",\n",
    "        \"apparent_temperature_mean\",\n",
    "        \"sunrise\",\n",
    "        \"sunset\",\n",
    "        \"precipitation_sum\",\n",
    "        \"rain_sum\",\n",
    "        \"showers_sum\",\n",
    "        \"snowfall_sum\",\n",
    "        \"precipitation_hours\",\n",
    "        \"wind_speed_10m_max\",\n",
    "        \"wind_direction_10m_dominant\",\n",
    "        \"shortwave_radiation_sum\",\n",
    "        \"et0_fao_evapotranspiration\"\n",
    "    ],\n",
    "    \"timezone\": \"auto\"\n",
    "}\n",
    "\n",
    "\n",
    "# 6. Make the API request\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Assuming only one location is queried, get the first response\n",
    "response = responses[0]\n",
    "\n",
    "# Process daily data\n",
    "daily = response.Daily()\n",
    "\n",
    "daily_data = {\n",
    "    \"date\": pd.date_range(\n",
    "        start=pd.to_datetime(daily.Time(), unit=\"s\"),\n",
    "        end=pd.to_datetime(daily.TimeEnd(), unit=\"s\"),\n",
    "        freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "        inclusive=\"left\"\n",
    "    )\n",
    "}\n",
    "\n",
    "for i, param in enumerate(params[\"daily\"]):\n",
    "    daily_data[param] = daily.Variables(i).Values(0)\n",
    "\n",
    "df_weather = pd.DataFrame(daily_data)\n"
   ],
   "id": "e858599d55830389",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "25f63357cd265a2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T23:50:23.745579Z",
     "start_time": "2026-02-03T23:50:23.713551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "# Install necessary packages to ensure a fresh environment\n",
    "# !pip install --upgrade --force-reinstall openmeteo-requests requests-cache retry-requests\n",
    "\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "import numpy as np # Import numpy for NaNs\n",
    "from retry_requests import retry\n",
    "\n",
    "# 2. Create a requests_cache.CachedSession object to cache API responses\n",
    "# Cache API requests for an hour to reduce redundant calls\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "\n",
    "# 3. Initialize the openmeteo_requests client with the cached session\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "# Define Abuja coordinates (re-added for scope)\n",
    "abuja_latitude = 9.0765\n",
    "abuja_longitude = 7.3986\n",
    "\n",
    "# 4. Define the URL for the Open-Meteo Archive API\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# 5. Specify the parameters for the API request\n",
    "params = {\n",
    "    \"latitude\": abuja_latitude,\n",
    "    \"longitude\": abuja_longitude,\n",
    "    \"start_date\": \"2000-01-01\", # Example start date, can be adjusted\n",
    "    \"end_date\": \"2023-12-31\",   # Example end date, ideally yesterday's date\n",
    "    \"daily\": [\n",
    "        \"weather_code\",\n",
    "        \"temperature_2m_max\",\n",
    "        \"temperature_2m_min\",\n",
    "        \"temperature_2m_mean\",\n",
    "        \"apparent_temperature_max\",\n",
    "        \"apparent_temperature_min\",\n",
    "        \"apparent_temperature_mean\",\n",
    "        \"sunrise\",\n",
    "        \"sunset\",\n",
    "        \"precipitation_sum\",\n",
    "        \"rain_sum\",\n",
    "        \"showers_sum\",\n",
    "        \"snowfall_sum\",\n",
    "        \"precipitation_hours\",\n",
    "        \"wind_speed_10m_max\",\n",
    "        # Removed 'wind_gust_speed_max' due to previous error\n",
    "        \"wind_direction_10m_dominant\",\n",
    "        \"shortwave_radiation_sum\",\n",
    "        \"et0_fao_evapotranspiration\"\n",
    "    ],\n",
    "    \"timezone\": \"auto\"\n",
    "}\n",
    "\n",
    "# 6. Make the API request using the client's weather_api method directly\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Assuming only one location is queried, get the first response\n",
    "response = responses[0]\n",
    "\n",
    "# Process daily data\n",
    "daily = response.Daily()\n",
    "\n",
    "# Check if daily data is actually available\n",
    "if daily is None:\n",
    "    print(\"No daily data found in the API response.\")\n",
    "    df_weather = pd.DataFrame() # Create empty DataFrame\n",
    "elif daily.VariablesLength() == 0:\n",
    "    print(\"No daily variables found in the API response. Creating empty DataFrame.\")\n",
    "    df_weather = pd.DataFrame()\n",
    "else:\n",
    "    # Determine the number of days from the first variable's data length\n",
    "    # This is more robust if daily.Time() is misbehaving\n",
    "    num_days = len(daily.Variables(0).ValuesAsNumpy())\n",
    "\n",
    "    # Extract date/time information\n",
    "    times = daily.Time()\n",
    "    if isinstance(times, (int, float)):\n",
    "        # If it's a scalar, assume it's the start time and generate a range\n",
    "        date_range = pd.date_range(start=pd.to_datetime(times, unit='s'), periods=num_days, freq='D')\n",
    "        daily_data = {\"date\": date_range}\n",
    "    elif times is not None and len(times) == num_days:\n",
    "        daily_data = {\"date\": pd.to_datetime(times, unit='s')}\n",
    "    else:\n",
    "        # Fallback if times is not int/float, not None, and length mismatch\n",
    "        print(f\"Warning: Time data length mismatch. Expected {num_days}, got {len(times) if times is not None else 'None'}. Generating date range.\")\n",
    "        start_time_unix = daily.Time()[0] if times is not None and hasattr(times, '__getitem__') else pd.Timestamp(params['start_date']).timestamp()\n",
    "        date_range = pd.date_range(start=pd.to_datetime(start_time_unix, unit='s'), periods=num_days, freq='D')\n",
    "        daily_data = {\"date\": date_range}\n",
    "\n",
    "    # Initialize daily_data for all requested parameters with NaN arrays\n",
    "    # This ensures all requested columns are present even if data is missing\n",
    "    for param in params[\"daily\"]:\n",
    "        daily_data[param] = np.full(num_days, np.nan)\n",
    "\n",
    "    # Extract daily variables using ValuesAsNumpy()\n",
    "    # Rely on the order of `daily.Variables(i)` matching `params[\"daily\"]`\n",
    "    for i, param_name_from_request in enumerate(params[\"daily\"]):\n",
    "        if i < daily.VariablesLength():\n",
    "            variable = daily.Variables(i)\n",
    "            try:\n",
    "                values = variable.ValuesAsNumpy()\n",
    "                if len(values) == num_days:\n",
    "                    daily_data[param_name_from_request] = values\n",
    "                else:\n",
    "                    print(f\"Warning: Data length mismatch for '{param_name_from_request}'. Expected {num_days}, got {len(values)}. Filling with NaNs.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting '{param_name_from_request}' values: {e}. Filling with NaNs.\")\n",
    "        else:\n",
    "            print(f\"Warning: Parameter '{param_name_from_request}' requested but no corresponding variable found in API response. Filling with NaNs.\")\n",
    "\n",
    "\n",
    "    # 7. Convert to Pandas DataFrame\n",
    "    df_weather = pd.DataFrame(daily_data)\n",
    "\n",
    "    # Set 'date' as index\n",
    "    df_weather = df_weather.set_index('date')\n",
    "\n",
    "# 8. Display the first few rows of the DataFrame\n",
    "print(\"Historical Weather Data for Abuja:\")\n",
    "if not df_weather.empty:\n",
    "    print(df_weather.head())\n",
    "    print(f\"\\nDataFrame shape: {df_weather.shape}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")"
   ],
   "id": "1d04b080cbd2a8f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting 'sunrise' values: object of type 'int' has no len(). Filling with NaNs.\n",
      "Error extracting 'sunset' values: object of type 'int' has no len(). Filling with NaNs.\n",
      "Historical Weather Data for Abuja:\n",
      "                     weather_code  temperature_2m_max  temperature_2m_min  \\\n",
      "date                                                                        \n",
      "1999-12-31 23:00:00           2.0           34.332001           22.882000   \n",
      "2000-01-01 23:00:00           3.0           34.632000           22.431999   \n",
      "2000-01-02 23:00:00           3.0           35.181999           23.431999   \n",
      "2000-01-03 23:00:00           3.0           34.281998           23.581999   \n",
      "2000-01-04 23:00:00           3.0           34.931999           22.382000   \n",
      "\n",
      "                     temperature_2m_mean  apparent_temperature_max  \\\n",
      "date                                                                 \n",
      "1999-12-31 23:00:00            28.802834                 34.801472   \n",
      "2000-01-01 23:00:00            28.563242                 35.943035   \n",
      "2000-01-02 23:00:00            29.129919                 35.945816   \n",
      "2000-01-03 23:00:00            28.823664                 34.895729   \n",
      "2000-01-04 23:00:00            28.640329                 35.830246   \n",
      "\n",
      "                     apparent_temperature_min  apparent_temperature_mean  \\\n",
      "date                                                                       \n",
      "1999-12-31 23:00:00                 23.141737                  29.113525   \n",
      "2000-01-01 23:00:00                 21.133766                  28.630796   \n",
      "2000-01-02 23:00:00                 20.986599                  28.635401   \n",
      "2000-01-03 23:00:00                 20.247787                  27.337175   \n",
      "2000-01-04 23:00:00                 19.999706                  27.381811   \n",
      "\n",
      "                     sunrise  sunset  precipitation_sum  rain_sum  \\\n",
      "date                                                                \n",
      "1999-12-31 23:00:00      NaN     NaN                0.0       0.0   \n",
      "2000-01-01 23:00:00      NaN     NaN                0.0       0.0   \n",
      "2000-01-02 23:00:00      NaN     NaN                0.0       0.0   \n",
      "2000-01-03 23:00:00      NaN     NaN                0.0       0.0   \n",
      "2000-01-04 23:00:00      NaN     NaN                0.0       0.0   \n",
      "\n",
      "                     showers_sum  snowfall_sum  precipitation_hours  \\\n",
      "date                                                                  \n",
      "1999-12-31 23:00:00          0.0           0.0                  0.0   \n",
      "2000-01-01 23:00:00          0.0           0.0                  0.0   \n",
      "2000-01-02 23:00:00          0.0           0.0                  0.0   \n",
      "2000-01-03 23:00:00          0.0           0.0                  0.0   \n",
      "2000-01-04 23:00:00          0.0           0.0                  0.0   \n",
      "\n",
      "                     wind_speed_10m_max  wind_direction_10m_dominant  \\\n",
      "date                                                                   \n",
      "1999-12-31 23:00:00            6.193674                   136.582367   \n",
      "2000-01-01 23:00:00            7.244860                    95.440254   \n",
      "2000-01-02 23:00:00            9.000000                    85.575294   \n",
      "2000-01-03 23:00:00           13.608762                    74.583344   \n",
      "2000-01-04 23:00:00            9.585739                    23.363007   \n",
      "\n",
      "                     shortwave_radiation_sum  et0_fao_evapotranspiration  \n",
      "date                                                                      \n",
      "1999-12-31 23:00:00                20.889999                    4.958117  \n",
      "2000-01-01 23:00:00                20.360001                    5.118730  \n",
      "2000-01-02 23:00:00                21.309999                    5.641002  \n",
      "2000-01-03 23:00:00                21.330000                    6.181933  \n",
      "2000-01-04 23:00:00                21.590000                    5.613385  \n",
      "\n",
      "DataFrame shape: (8766, 18)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T23:50:32.465883Z",
     "start_time": "2026-02-03T23:50:32.442311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Define the target variable 'is_rain'\n",
    "# Set 'is_rain' to 1 if precipitation_sum > 0.0, and 0 otherwise\n",
    "df_weather['is_rain'] = (df_weather['precipitation_sum'] > 0.0).astype(int)\n",
    "\n",
    "# 2. Extract temporal features from the DataFrame's index\n",
    "df_weather['year'] = df_weather.index.year\n",
    "df_weather['month'] = df_weather.index.month\n",
    "df_weather['day'] = df_weather.index.day\n",
    "\n",
    "# 3. Select and prepare features for the model\n",
    "# Exclude 'date' (which is the index now) and the target variable 'is_rain'\n",
    "# Also exclude 'sunrise' and 'sunset' as they consistently have NaNs from the API response and are less direct for rain prediction\n",
    "# 'weather_code' is categorical and should be handled separately or one-hot encoded for some models, for simplicity we'll keep it numerical for now.\n",
    "# Remove 'precipitation_sum' as it's directly used to create 'is_rain' and would cause data leakage.\n",
    "feature_columns = [\n",
    "    'weather_code',\n",
    "    'temperature_2m_max',\n",
    "    'temperature_2m_min',\n",
    "    'temperature_2m_mean',\n",
    "    'apparent_temperature_max',\n",
    "    'apparent_temperature_min',\n",
    "    'apparent_temperature_mean',\n",
    "    'rain_sum',\n",
    "    'showers_sum',\n",
    "    'snowfall_sum',\n",
    "    'precipitation_hours',\n",
    "    'wind_speed_10m_max',\n",
    "    'wind_direction_10m_dominant',\n",
    "    'shortwave_radiation_sum',\n",
    "    'et0_fao_evapotranspiration',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day'\n",
    "]\n",
    "\n",
    "# Filter df_weather to include only feature columns and the target variable for further processing\n",
    "df_model = df_weather[feature_columns + ['is_rain']].copy()\n",
    "\n",
    "# 4. Handle missing values\n",
    "# Fill NaN values in feature columns with the mean of their respective columns\n",
    "for col in feature_columns:\n",
    "    if df_model[col].isnull().any():\n",
    "        df_model[col] = df_model[col].fillna(df_model[col].mean())\n",
    "\n",
    "# Check for any remaining NaNs in the target variable and fill with 0 if any (assuming no rain if data is missing)\n",
    "if df_model['is_rain'].isnull().any():\n",
    "    df_model['is_rain'] = df_model['is_rain'].fillna(0).astype(int)\n",
    "\n",
    "# Display the first few rows of the preprocessed DataFrame and its info to verify\n",
    "print(\"Preprocessed DataFrame for ML Model:\")\n",
    "print(df_model.head())\n",
    "print(f\"\\nDataFrame shape: {df_model.shape}\")\n",
    "print(\"\\nMissing values after preprocessing:\")\n",
    "print(df_model.isnull().sum())\n"
   ],
   "id": "fccf594c1a8b74d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed DataFrame for ML Model:\n",
      "                     weather_code  temperature_2m_max  temperature_2m_min  \\\n",
      "date                                                                        \n",
      "1999-12-31 23:00:00           2.0           34.332001           22.882000   \n",
      "2000-01-01 23:00:00           3.0           34.632000           22.431999   \n",
      "2000-01-02 23:00:00           3.0           35.181999           23.431999   \n",
      "2000-01-03 23:00:00           3.0           34.281998           23.581999   \n",
      "2000-01-04 23:00:00           3.0           34.931999           22.382000   \n",
      "\n",
      "                     temperature_2m_mean  apparent_temperature_max  \\\n",
      "date                                                                 \n",
      "1999-12-31 23:00:00            28.802834                 34.801472   \n",
      "2000-01-01 23:00:00            28.563242                 35.943035   \n",
      "2000-01-02 23:00:00            29.129919                 35.945816   \n",
      "2000-01-03 23:00:00            28.823664                 34.895729   \n",
      "2000-01-04 23:00:00            28.640329                 35.830246   \n",
      "\n",
      "                     apparent_temperature_min  apparent_temperature_mean  \\\n",
      "date                                                                       \n",
      "1999-12-31 23:00:00                 23.141737                  29.113525   \n",
      "2000-01-01 23:00:00                 21.133766                  28.630796   \n",
      "2000-01-02 23:00:00                 20.986599                  28.635401   \n",
      "2000-01-03 23:00:00                 20.247787                  27.337175   \n",
      "2000-01-04 23:00:00                 19.999706                  27.381811   \n",
      "\n",
      "                     rain_sum  showers_sum  snowfall_sum  precipitation_hours  \\\n",
      "date                                                                            \n",
      "1999-12-31 23:00:00       0.0          0.0           0.0                  0.0   \n",
      "2000-01-01 23:00:00       0.0          0.0           0.0                  0.0   \n",
      "2000-01-02 23:00:00       0.0          0.0           0.0                  0.0   \n",
      "2000-01-03 23:00:00       0.0          0.0           0.0                  0.0   \n",
      "2000-01-04 23:00:00       0.0          0.0           0.0                  0.0   \n",
      "\n",
      "                     wind_speed_10m_max  wind_direction_10m_dominant  \\\n",
      "date                                                                   \n",
      "1999-12-31 23:00:00            6.193674                   136.582367   \n",
      "2000-01-01 23:00:00            7.244860                    95.440254   \n",
      "2000-01-02 23:00:00            9.000000                    85.575294   \n",
      "2000-01-03 23:00:00           13.608762                    74.583344   \n",
      "2000-01-04 23:00:00            9.585739                    23.363007   \n",
      "\n",
      "                     shortwave_radiation_sum  et0_fao_evapotranspiration  \\\n",
      "date                                                                       \n",
      "1999-12-31 23:00:00                20.889999                    4.958117   \n",
      "2000-01-01 23:00:00                20.360001                    5.118730   \n",
      "2000-01-02 23:00:00                21.309999                    5.641002   \n",
      "2000-01-03 23:00:00                21.330000                    6.181933   \n",
      "2000-01-04 23:00:00                21.590000                    5.613385   \n",
      "\n",
      "                     year  month  day  is_rain  \n",
      "date                                            \n",
      "1999-12-31 23:00:00  1999     12   31        0  \n",
      "2000-01-01 23:00:00  2000      1    1        0  \n",
      "2000-01-02 23:00:00  2000      1    2        0  \n",
      "2000-01-03 23:00:00  2000      1    3        0  \n",
      "2000-01-04 23:00:00  2000      1    4        0  \n",
      "\n",
      "DataFrame shape: (8766, 19)\n",
      "\n",
      "Missing values after preprocessing:\n",
      "weather_code                   0\n",
      "temperature_2m_max             0\n",
      "temperature_2m_min             0\n",
      "temperature_2m_mean            0\n",
      "apparent_temperature_max       0\n",
      "apparent_temperature_min       0\n",
      "apparent_temperature_mean      0\n",
      "rain_sum                       0\n",
      "showers_sum                    0\n",
      "snowfall_sum                   0\n",
      "precipitation_hours            0\n",
      "wind_speed_10m_max             0\n",
      "wind_direction_10m_dominant    0\n",
      "shortwave_radiation_sum        0\n",
      "et0_fao_evapotranspiration     0\n",
      "year                           0\n",
      "month                          0\n",
      "day                            0\n",
      "is_rain                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "c0bcc60e25cfbb17",
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T23:50:47.232261Z",
     "start_time": "2026-02-03T23:50:36.473920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# 1. Define features (X) and target (y)\n",
    "X = df_model.drop('is_rain', axis=1)\n",
    "y = df_model['is_rain']\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(f\"X_train shape: {X_train.shape}\")\n",
    "# print(f\"X_test shape: {X_test.shape}\")\n",
    "# print(f\"y_train shape: {y_train.shape}\")\n",
    "# print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# 3. Instantiate a RandomForestClassifier model\n",
    "# Using n_estimators=100 and random_state=42 for consistent results\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 4. Train the RandomForestClassifier model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1] # Probability of the positive class (rain)\n",
    "\n"
   ],
   "id": "4bcdb7e54b76e1fe",
   "outputs": [],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
